<!DOCTYPE html>
<html lang="en-US">
   
<title>Academic Thoughts</title>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">  

</head>

<!--<link rel='stylesheet' id='gmlaunch-style-css'  href='https://149366099.v2.pressablecdn.com/wp-content/themes/farnamstreet/style.css?ver=5.4.1' type='text/css' media='all' />-->
<!--<link rel='stylesheet' id='gmlaunch-format-css'  href='https://149366099.v2.pressablecdn.com/wp-content/themes/farnamstreet/css/format.css?ver=1587683036' type='text/css' media='all' />-->
<link rel='stylesheet' id='gmlaunch-style-css'  href='style.css' type='text/css' media='all' />
<link rel='stylesheet' id='gmlaunch-format-css'  href='format.css' type='text/css' media='all' />
<link rel="icon" href="favicon.ico" type="image/x-icon">
<div id="content" class="site-content">
<div id="primary" class="content-area">
<main id="main" class="site-main" role="main">
<div class="full">
<div class="content section-page-default">
<div class="column75 column-center">

<h1 class="page-title">Academic Thoughts</h1>
                    <i><big style="color: #5c616d;">The Search</big></i>:<br>
                    <p><font size="+0"> Since centuries, humans have been attempting to understand the principles that make the <i>mind</i> and that lead to <i>intelligence</i>. Understanding what intelligence is, how to simulate it and make it a reality, how to develop intelligence much more capable than what we ever know of has been a long-standing goal of humanity. It is one of the mightiest goals we know of that even the process of attempting it is a humbling and a fruitful exercise. It is one of the most common questions that many of us ponder over at some point in our life and conclude to incomplete answers. This is my small attempt in finding these answers. I share the same curiosity, passion, and enthusiasm that many others who attempt this goal have. I hope that in my lifetime, we complete the missing pieces of this giant puzzle. 
                    </font></p>
                    <i><big style="color: #5c616d;">An Approach</big></i>:<br>
                    <p><font size="+0">
                        Currently, my research interests lie in <i>reinforcement learning</i>, <i>representation learning</i>, and <i>real-world reinforcement learning</i>. I care about building intelligent agents that are grounded in interaction with their environment. Such agents should make use of domain independent, general-purpose learning mechanisms, architectures and algorithms.
                        Such agents should be able to improve their ability to learn with more experience and should be able to adapt to any environment they are placed in, while respecting the inherent constraints on the agents.
                    </font></p>
                    
                    <p><font size="+0"> I care about <i>reinforcement learning</i> as it is a powerful framework that explains how intelligence can emerge in agents solely on the basis of their interaction with the world around them. I thoroughly enjoy studying and working in <i>reinforcement learning</i>, as it brings together ideas from several areas of knowledge like <i>psychology</i>, <i>neuroscience</i>, and <i>computing science</i>, making it a very rewarding subject to study. Personally, I also think it has ties to <i>philosophy</i> as many parallels can be drawn between <i>life</i> and the <i>reinforcement learning</i> framework.
                    </font></p>
                    <p><font size="+0"> I care about <i>representation learning</i> because it forms the basis on which learning is dependent. Many components in the <i>reinforcement learning</i> framework rely on good representations. Good representations should lead to better performance, generalization, and no interference/forgetting. With respect to this, I care about constructing the agent state, which is the agent's perception of where it is in the environment. This includes how well the representations summarize the past history, convey the present state, and predict the future. In light of this, I care about <i>general value functions</i> for prediction-based state representation and also <i>discovery/search of good state features</i>. The idea of discovery of representations, hyperparameters, architectures, and learning algorithms with minimal hand-designed components is powerful and general, and is a potential direction to general intelligence. Recently, I have been interested in this study of discovery which is also referred to as <i>learning to learn</i> or <i>meta-learning</i>.
                        Representation learning naturally leads to my interest in function approximation methods like <i>deep learning</i>.  
                    </font></p>
                    <p><font size="+0"> I care about <i>real-world reinforcement learning</i>, especially its application in industrial control and in robotics. Most of the work done today is in the simulated domain as against the real-world where the agents of the future will be operating. Real-world brings many challenges that are important to be addressed but are not explored to the fullest in simulated domains. Today, reinforcement learning is sample inefficient and this characteristic is not very suitable in the real-world where the data rate is much lower than simulated worlds. However, it is important to note that the most gains will also be from its application in the real-world once it is viable.  
                    </font></p>
                    <p><font size="+0"> Accordingly, I have been studying and working in these areas in different capacities.</font></p>

</body>
</html>
